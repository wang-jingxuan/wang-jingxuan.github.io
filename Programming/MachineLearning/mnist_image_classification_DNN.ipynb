{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89a7b8f",
   "metadata": {},
   "source": [
    "# Mnist Image Classification by DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45510f3",
   "metadata": {},
   "source": [
    "## 1. Fire Up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de01888c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sympy\n",
    "from sympy import Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8080cf",
   "metadata": {},
   "source": [
    "## 2. Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dbff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.FloatTensor([[0.1, 0.2, 0.7], [0.2, 0.3, 0.5]]).reshape(2, 3)\n",
    "print(out)\n",
    "label = torch.LongTensor([2, 1])\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768aeef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = n.CrossEntropyLoss()\n",
    "print(loss_function(out, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a926b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = p.log (np.exp(0.1) + np.exp(0.7) + np.exp(0.2)) - 0.7\n",
    "print(a)\n",
    "b = np.log(np.exp(0.2) + np.exp(0.3) + np.exp(0.5)) - 0.3\n",
    "print (b)\n",
    "print(\"loss =\", (a + b) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b3b59",
   "metadata": {},
   "source": [
    "## 3. Data Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = keras.datasets.mnist\n",
    "(data_train, label_train), (data_test, label_test) = mist_dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f04bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Training Samples\n",
    "print(data_train.__len__())\n",
    "print (label_train.__len__())\n",
    "# Number of Test Samples\n",
    "print(data_test.__len__())\n",
    "print(label_test.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93168ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix(data_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(data_train[0])\n",
    "print(\"The label for image[0] is\", label_train[0])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(data_train[59999])\n",
    "print (\"The label for image[59999] is\", label_train [59999]) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc11195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy.ndarry data to tensor type in Pytorch\n",
    "data_train = Variable(torch.FloatTensor(data_train)) / 255.0\n",
    "data_test = Variable(torch.FloatTensor(data_test)) / 255.0\n",
    "label_train = Variable(torch.LongTensor(label_train))\n",
    "label_test = Variable(torch.LongTensor(label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650a402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a 28 × 28 Matrix into a 784 × 1 Vector \n",
    "data_train[0].reshape(1, -1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1a4301",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    # Constructor of the class\n",
    "    def __init__(self, input_dim1, output_dim1, input_dim2, output_dim2,\n",
    "               input_dim3, output_dim3):\n",
    "        super(DeepNeuralNetworkModel, self).__init__()\n",
    "        \n",
    "        # Fully Connected Layer 1\n",
    "        self.FC_layer1 = nn.Linear(input_dim1, output_dim1)\n",
    "        #nn.init.constant_(self.FC_layer1.weight, 0.1)\n",
    "        #nn.init.constant_(self.FC_layer1.bias, -0.1)\n",
    "        \n",
    "        # Fully Connected Layer 2\n",
    "        self.FC_layer2 = nn.Linear(input_dim2, output_dim2)\n",
    "        \n",
    "        # Fully Connected Layer 3\n",
    "        self.FC_layer3 = nn.Linear(input_dim3, output_dim3)\n",
    "        \n",
    "        # Activation Function Sigmoid()\n",
    "        self.act_sig = nn.Sigmoid()\n",
    "        \n",
    "        # Activation Function ReLU()\n",
    "        self.act_relu = nn.ReLU()\n",
    "        \n",
    "    # Forward propagation function\n",
    "    def forward(self, x):    # dim of x: N × input_diml\n",
    "        \n",
    "        z1_ = self.FC_layer1(x)\n",
    "        z1 = self.act_sig(z1_)\n",
    "\n",
    "        z2_ = self.FC_layer2(z1)\n",
    "        z2 = self.act_sig(z2_)\n",
    "        \n",
    "        z3_ = self.FC_layer3(z2)\n",
    "        # z3 = self.act_relu(z3_)\n",
    "        \n",
    "        return z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c73a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "DNN_Model = DeepNeuraletworkModel(784, 128, 128, 64, 64, 10)\n",
    "optimizer = torch.optim.SGD(DNN_Model.parameters(), lr = alpha)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Dynamically Change the learning rate\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    if epoch <= 100:\n",
    "        lr = alpha\n",
    "        \n",
    "    elif epoch > 100:\n",
    "        lr = alpha / (1 + 0.01 * (epoch - 100))\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a524c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "batch size = 10000\n",
    "batches = int((data_train.__Len__ ()) / batch size)\n",
    "col = 28 * 28\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch in range(batches):\n",
    "        \n",
    "        # Get the input data matrix: dim = 100 × 784\n",
    "        input_data = Variable(torch. FloatTensor(batch_size, col))\n",
    "        for j in range(batch_size):\n",
    "            input_data[j] = data_train[j + batch_size * batch].reshape(1, -1)\n",
    "            \n",
    "            # Forward propagation: output_data has dim = 100 × 10\n",
    "            output_data = DNN_Model.forward(input_data)\n",
    "            \n",
    "            # Compute cross entropy loss\n",
    "            loss = loss_function(output_data, label_train[batch_size * batch : batch_size * (batch + 1)])\n",
    "            \n",
    "            # backward propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Reset grad to 0\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Save loss for this batch\n",
    "            loss_list.append(loss)\n",
    "\n",
    "            # Print details for the gradient descent\n",
    "            if(epoch) % 10 == 0 and (batch + 1) % 1 == 0:\n",
    "                print(\"epoch =\", epoch + 1, \"; \", \"batch =\", batch + 1, \":\")\n",
    "                print(\"      -> Now loss =\", loss.item())\n",
    "                print(\"-------------------------------------------------------------\")\n",
    "            \n",
    "        adjust_learning_rate(optimizer, epoch) \n",
    "        \n",
    "        if(epoch) % 10 == 0:\n",
    "            print(\"*********************** Epoch\",epoch + 1, \"Over **********************\")\n",
    "            print(\" \")\n",
    "            print(\" \")\n",
    "        \n",
    "        if loss < 0.74:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793b015c",
   "metadata": {},
   "source": [
    "## 5. Visualization of the Cross Entropy Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14, 6))\n",
    "length = loss_list.__len__()\n",
    "print(\"The length of loss_list is:\", length) \n",
    "plt.plot(np.arange (1, length + 1, 1), loss_list, \"black\") \n",
    "plt.xlabel(\"epoch\") \n",
    "plt.ylabel (\"loss\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6778ebd",
   "metadata": {},
   "source": [
    "## 6. Prediction on the Test Set and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8442fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e9b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data_test[0])\n",
    "print(\"The label of this image is:\", label_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31273d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vec = DNN_Model.forward(data_test[0]. reshape(1, -1))\n",
    "print(\"Prediction for data_test[0]:\")\n",
    "Matrix(pred_vec.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e2515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_distribution = F.softmax(DNN_Model.forward(data_test[0].reshape(1, -1)), dim = 1)\n",
    "print(\"Probability distribution for the prediction of data_test[0]:\")\n",
    "print(\"    ->The argmax of the probability distribution vector is:\", \n",
    "      torch.argmax(proba_distribution).detach().numpy())\n",
    "print(\"    ->Sum of the probability distribution vector is:\", torch.sum(proba_distribution).detach().numpy())\n",
    "Matrix(proba_distribution.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02491cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in range(data_test.__len__()):\n",
    "    temp_distribution = F.softmax(DNN_Model.forward(data_test[i].reshape(1, -1)), dim = 1)\n",
    "    pred.append(torch.argmax(temp_distribution).detach().numpy ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a188373",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy score is:\", 100.0 * accuracy_score(label_test, pred), \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Jingxuan Wang">
      
      
        <meta name="author" content="Jingxuan Wang">
      
      
        <link rel="canonical" href="https://wang-jingxuan.github.io/Programming/MachineLearning/pytorch_logistic_regerssion/pytorch_logistic_regerssion/">
      
      
        <link rel="prev" href="../../Perfume_Grouping/Perfume_Grouping/">
      
      
        <link rel="next" href="../../pytorch_DNN/pytorch_DNN/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.9">
    
    
      
        <title>Logistic Regression - Jingxuan Wang</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../mkdocs/css/no-footer.css">
    
      <link rel="stylesheet" href="../../../../mkdocs/css/unordered-list-symbols.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="amber" data-md-color-accent="cyan">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pytorch-logistic-regression" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Jingxuan Wang" class="md-header__button md-logo" aria-label="Jingxuan Wang" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Jingxuan Wang
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Logistic Regression
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="amber" data-md-color-accent="cyan"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="amber" data-md-color-accent="cyan"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/wang-jingxuan/wang-jingxuan.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    wang-jingxuan.github.io
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../CV/" class="md-tabs__link">
        
  
    
  
  CV

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../" class="md-tabs__link">
          
  
    
  
  Programming

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../AboutMe/" class="md-tabs__link">
        
  
    
  
  About Me

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Jingxuan Wang" class="md-nav__button md-logo" aria-label="Jingxuan Wang" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Jingxuan Wang
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/wang-jingxuan/wang-jingxuan.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    wang-jingxuan.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../CV/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CV
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Programming
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Programming
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Machine Learning
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Machine Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Perfume_Grouping/Perfume_Grouping/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Clustering Data
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Logistic Regression
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Logistic Regression
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-fire-up" class="md-nav__link">
    <span class="md-ellipsis">
      1. Fire up
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-data-generating" class="md-nav__link">
    <span class="md-ellipsis">
      2. Data generating
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-model-training" class="md-nav__link">
    <span class="md-ellipsis">
      3. Model training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-visualization-of-the-cross-entropy-function" class="md-nav__link">
    <span class="md-ellipsis">
      4. Visualization of the Cross Entropy Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-prediction-on-the-test-set-and-model-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      5. Prediction on the test set and model evaluation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch_DNN/pytorch_DNN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deep Neural Networks (DNN)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch_convolutional_neural_network%28CNN%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Convolutional Neural Network (CNN)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mnist_image_classification_DNN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image Classification
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pytorch_SVM_algorithm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SVM Algorithm
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../Reprint/TwoSigma_StockMarket%20Prediction_Reprint/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Reprint - Two Sigma Stock Market Prediction
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Reprint - Two Sigma Stock Market Prediction
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Reprint/TwoSigma_StockMarket%20Prediction_Reprint/Two%20Sigma%20Market%20EDA/Two%20Sigma%20Market%20EDA/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Market EDA
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Reprint/TwoSigma_StockMarket%20Prediction_Reprint/Two%20Sigma%20News%20EDA/Two%20Sigma%20News%20EDA/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    News EDA
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Reprint/TwoSigma_StockMarket%20Prediction_Reprint/Two%20sigma%20Merging%20and%20Data%20prepocessing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Merging and Data preprocessing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Reprint/TwoSigma_StockMarket%20Prediction_Reprint/Two%20Sigma%20Modeling/Two%20Sigma%20Modeling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modeling
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../AboutMe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About Me
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-fire-up" class="md-nav__link">
    <span class="md-ellipsis">
      1. Fire up
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-data-generating" class="md-nav__link">
    <span class="md-ellipsis">
      2. Data generating
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-model-training" class="md-nav__link">
    <span class="md-ellipsis">
      3. Model training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-visualization-of-the-cross-entropy-function" class="md-nav__link">
    <span class="md-ellipsis">
      4. Visualization of the Cross Entropy Function
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-prediction-on-the-test-set-and-model-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      5. Prediction on the test set and model evaluation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/wang-jingxuan/wang-jingxuan.github.io/edit/main/docs/Programming/MachineLearning/pytorch_logistic_regerssion/pytorch_logistic_regerssion.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


<h1 id="pytorch-logistic-regression">Pytorch logistic regression<a class="headerlink" href="#pytorch-logistic-regression" title="Permanent link">&para;</a></h1>
<h2 id="1-fire-up">1. Fire up<a class="headerlink" href="#1-fire-up" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.autograd</span><span class="w"> </span><span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>
</code></pre></div>
<h2 id="2-data-generating">2. Data generating<a class="headerlink" href="#2-data-generating" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_breast_cancer</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">data</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span> <span class="c1"># extract target</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># extract label</span>
</code></pre></div>
<p><code>reshape(-1, 1)</code>将目标变量从一维数组转换为二维数组的列向量形式,是NumPy数组的一种形状变换操作。它的作用是将数组从原始形状转换为新的形状，其中的 -1 表示自动推断维度大小。</p>
<p>这样处理是因为在scikit-learn中，目标变量通常需要是一个二维数组的列向量，其中每行对应一个样本的标签。</p>
<p>具体地，<code>reshape(-1, 1)</code>会将数组的第一个维度设为自动推断的值，而将第二个维度设为1。这样的操作实际上是将原始数组转换为一个列向量，其中每个元素独立占据一行。</p>
<p>举个例子，假设有一个一维数组 <code>arr = [1, 2, 3, 4, 5]</code>，通过 <code>arr.reshape(-1, 1)</code> 操作，可以得到一个列向量：</p>
<div class="highlight"><pre><span></span><code>[[1],
 [2],
 [3],
 [4],
 [5]]
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># 569个30维向量</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># 569个1维向量</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>(569, 30)
(569, 1)
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># 将数组或矩阵进行切片操作，用于将数据集分割为训练集和测试集</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="mi">500</span><span class="p">,:]</span> <span class="c1"># 对矩阵X进行切片，选择第0行到第499行（共500行）的所有列，即选取X的前500行作为训练集</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="mi">500</span><span class="p">,:]</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">500</span><span class="p">:,:]</span> <span class="c1"># 对矩阵X进行切片，选择从第500行开始到最后一行的所有列，即选取X的第500行及以后的所有行作为测试集</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">500</span><span class="p">:,:]</span>
</code></pre></div>
<p>在这里，<code>:</code>表示选取所有元素的范围，用于指定切片的起始和结束位置，如<code>a[:500]</code>表示选取数组a的前500个元素。</p>
<p>对于二维数组或矩阵，可以使用<code>:</code>对行和列同时进行切片操作，如<code>a[:500, :]</code>表示选取前500行的所有列。</p>
<div class="highlight"><pre><span></span><code><span class="c1"># 将 NumPy 数组转换为 Pandas DataFrame 对象</span>
<span class="n">training_X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">training_y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">test_X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">test_y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
</code></pre></div>
<p>DataFrame类似于表格或电子表格，可以存储和操作二维数据。</p>
<p>这样做的目的可能是为了方便后续使用 Pandas 提供的数据分析和处理功能，比如进行数据预处理、特征工程、模型训练等。</p>
<p>Pandas 的 DataFrame 提供了更多灵活的数据操作和分析方法，能够更方便地处理和探索数据。</p>
<div class="highlight"><pre><span></span><code><span class="n">training_X</span>
</code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>20</th>
      <th>21</th>
      <th>22</th>
      <th>23</th>
      <th>24</th>
      <th>25</th>
      <th>26</th>
      <th>27</th>
      <th>28</th>
      <th>29</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17.99</td>
      <td>10.38</td>
      <td>122.80</td>
      <td>1001.0</td>
      <td>0.11840</td>
      <td>0.27760</td>
      <td>0.30010</td>
      <td>0.14710</td>
      <td>0.2419</td>
      <td>0.07871</td>
      <td>...</td>
      <td>25.38</td>
      <td>17.33</td>
      <td>184.60</td>
      <td>2019.0</td>
      <td>0.1622</td>
      <td>0.6656</td>
      <td>0.7119</td>
      <td>0.2654</td>
      <td>0.4601</td>
      <td>0.11890</td>
    </tr>
    <tr>
      <th>1</th>
      <td>20.57</td>
      <td>17.77</td>
      <td>132.90</td>
      <td>1326.0</td>
      <td>0.08474</td>
      <td>0.07864</td>
      <td>0.08690</td>
      <td>0.07017</td>
      <td>0.1812</td>
      <td>0.05667</td>
      <td>...</td>
      <td>24.99</td>
      <td>23.41</td>
      <td>158.80</td>
      <td>1956.0</td>
      <td>0.1238</td>
      <td>0.1866</td>
      <td>0.2416</td>
      <td>0.1860</td>
      <td>0.2750</td>
      <td>0.08902</td>
    </tr>
    <tr>
      <th>2</th>
      <td>19.69</td>
      <td>21.25</td>
      <td>130.00</td>
      <td>1203.0</td>
      <td>0.10960</td>
      <td>0.15990</td>
      <td>0.19740</td>
      <td>0.12790</td>
      <td>0.2069</td>
      <td>0.05999</td>
      <td>...</td>
      <td>23.57</td>
      <td>25.53</td>
      <td>152.50</td>
      <td>1709.0</td>
      <td>0.1444</td>
      <td>0.4245</td>
      <td>0.4504</td>
      <td>0.2430</td>
      <td>0.3613</td>
      <td>0.08758</td>
    </tr>
    <tr>
      <th>3</th>
      <td>11.42</td>
      <td>20.38</td>
      <td>77.58</td>
      <td>386.1</td>
      <td>0.14250</td>
      <td>0.28390</td>
      <td>0.24140</td>
      <td>0.10520</td>
      <td>0.2597</td>
      <td>0.09744</td>
      <td>...</td>
      <td>14.91</td>
      <td>26.50</td>
      <td>98.87</td>
      <td>567.7</td>
      <td>0.2098</td>
      <td>0.8663</td>
      <td>0.6869</td>
      <td>0.2575</td>
      <td>0.6638</td>
      <td>0.17300</td>
    </tr>
    <tr>
      <th>4</th>
      <td>20.29</td>
      <td>14.34</td>
      <td>135.10</td>
      <td>1297.0</td>
      <td>0.10030</td>
      <td>0.13280</td>
      <td>0.19800</td>
      <td>0.10430</td>
      <td>0.1809</td>
      <td>0.05883</td>
      <td>...</td>
      <td>22.54</td>
      <td>16.67</td>
      <td>152.20</td>
      <td>1575.0</td>
      <td>0.1374</td>
      <td>0.2050</td>
      <td>0.4000</td>
      <td>0.1625</td>
      <td>0.2364</td>
      <td>0.07678</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>495</th>
      <td>14.87</td>
      <td>20.21</td>
      <td>96.12</td>
      <td>680.9</td>
      <td>0.09587</td>
      <td>0.08345</td>
      <td>0.06824</td>
      <td>0.04951</td>
      <td>0.1487</td>
      <td>0.05748</td>
      <td>...</td>
      <td>16.01</td>
      <td>28.48</td>
      <td>103.90</td>
      <td>783.6</td>
      <td>0.1216</td>
      <td>0.1388</td>
      <td>0.1700</td>
      <td>0.1017</td>
      <td>0.2369</td>
      <td>0.06599</td>
    </tr>
    <tr>
      <th>496</th>
      <td>12.65</td>
      <td>18.17</td>
      <td>82.69</td>
      <td>485.6</td>
      <td>0.10760</td>
      <td>0.13340</td>
      <td>0.08017</td>
      <td>0.05074</td>
      <td>0.1641</td>
      <td>0.06854</td>
      <td>...</td>
      <td>14.38</td>
      <td>22.15</td>
      <td>95.29</td>
      <td>633.7</td>
      <td>0.1533</td>
      <td>0.3842</td>
      <td>0.3582</td>
      <td>0.1407</td>
      <td>0.3230</td>
      <td>0.10330</td>
    </tr>
    <tr>
      <th>497</th>
      <td>12.47</td>
      <td>17.31</td>
      <td>80.45</td>
      <td>480.1</td>
      <td>0.08928</td>
      <td>0.07630</td>
      <td>0.03609</td>
      <td>0.02369</td>
      <td>0.1526</td>
      <td>0.06046</td>
      <td>...</td>
      <td>14.06</td>
      <td>24.34</td>
      <td>92.82</td>
      <td>607.3</td>
      <td>0.1276</td>
      <td>0.2506</td>
      <td>0.2028</td>
      <td>0.1053</td>
      <td>0.3035</td>
      <td>0.07661</td>
    </tr>
    <tr>
      <th>498</th>
      <td>18.49</td>
      <td>17.52</td>
      <td>121.30</td>
      <td>1068.0</td>
      <td>0.10120</td>
      <td>0.13170</td>
      <td>0.14910</td>
      <td>0.09183</td>
      <td>0.1832</td>
      <td>0.06697</td>
      <td>...</td>
      <td>22.75</td>
      <td>22.88</td>
      <td>146.40</td>
      <td>1600.0</td>
      <td>0.1412</td>
      <td>0.3089</td>
      <td>0.3533</td>
      <td>0.1663</td>
      <td>0.2510</td>
      <td>0.09445</td>
    </tr>
    <tr>
      <th>499</th>
      <td>20.59</td>
      <td>21.24</td>
      <td>137.80</td>
      <td>1320.0</td>
      <td>0.10850</td>
      <td>0.16440</td>
      <td>0.21880</td>
      <td>0.11210</td>
      <td>0.1848</td>
      <td>0.06222</td>
      <td>...</td>
      <td>23.86</td>
      <td>30.76</td>
      <td>163.20</td>
      <td>1760.0</td>
      <td>0.1464</td>
      <td>0.3597</td>
      <td>0.5179</td>
      <td>0.2113</td>
      <td>0.2480</td>
      <td>0.08999</td>
    </tr>
  </tbody>
</table>
<p>500 rows × 30 columns</p>
</div>

<div class="highlight"><pre><span></span><code><span class="n">test_X</span>
</code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>20</th>
      <th>21</th>
      <th>22</th>
      <th>23</th>
      <th>24</th>
      <th>25</th>
      <th>26</th>
      <th>27</th>
      <th>28</th>
      <th>29</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>15.040</td>
      <td>16.74</td>
      <td>98.73</td>
      <td>689.4</td>
      <td>0.09883</td>
      <td>0.13640</td>
      <td>0.07721</td>
      <td>0.06142</td>
      <td>0.1668</td>
      <td>0.06869</td>
      <td>...</td>
      <td>16.760</td>
      <td>20.43</td>
      <td>109.70</td>
      <td>856.9</td>
      <td>0.11350</td>
      <td>0.21760</td>
      <td>0.1856</td>
      <td>0.10180</td>
      <td>0.2177</td>
      <td>0.08549</td>
    </tr>
    <tr>
      <th>1</th>
      <td>13.820</td>
      <td>24.49</td>
      <td>92.33</td>
      <td>595.9</td>
      <td>0.11620</td>
      <td>0.16810</td>
      <td>0.13570</td>
      <td>0.06759</td>
      <td>0.2275</td>
      <td>0.07237</td>
      <td>...</td>
      <td>16.010</td>
      <td>32.94</td>
      <td>106.00</td>
      <td>788.0</td>
      <td>0.17940</td>
      <td>0.39660</td>
      <td>0.3381</td>
      <td>0.15210</td>
      <td>0.3651</td>
      <td>0.11830</td>
    </tr>
    <tr>
      <th>2</th>
      <td>12.540</td>
      <td>16.32</td>
      <td>81.25</td>
      <td>476.3</td>
      <td>0.11580</td>
      <td>0.10850</td>
      <td>0.05928</td>
      <td>0.03279</td>
      <td>0.1943</td>
      <td>0.06612</td>
      <td>...</td>
      <td>13.570</td>
      <td>21.40</td>
      <td>86.67</td>
      <td>552.0</td>
      <td>0.15800</td>
      <td>0.17510</td>
      <td>0.1889</td>
      <td>0.08411</td>
      <td>0.3155</td>
      <td>0.07538</td>
    </tr>
    <tr>
      <th>3</th>
      <td>23.090</td>
      <td>19.83</td>
      <td>152.10</td>
      <td>1682.0</td>
      <td>0.09342</td>
      <td>0.12750</td>
      <td>0.16760</td>
      <td>0.10030</td>
      <td>0.1505</td>
      <td>0.05484</td>
      <td>...</td>
      <td>30.790</td>
      <td>23.87</td>
      <td>211.50</td>
      <td>2782.0</td>
      <td>0.11990</td>
      <td>0.36250</td>
      <td>0.3794</td>
      <td>0.22640</td>
      <td>0.2908</td>
      <td>0.07277</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9.268</td>
      <td>12.87</td>
      <td>61.49</td>
      <td>248.7</td>
      <td>0.16340</td>
      <td>0.22390</td>
      <td>0.09730</td>
      <td>0.05252</td>
      <td>0.2378</td>
      <td>0.09502</td>
      <td>...</td>
      <td>10.280</td>
      <td>16.38</td>
      <td>69.05</td>
      <td>300.2</td>
      <td>0.19020</td>
      <td>0.34410</td>
      <td>0.2099</td>
      <td>0.10250</td>
      <td>0.3038</td>
      <td>0.12520</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>64</th>
      <td>21.560</td>
      <td>22.39</td>
      <td>142.00</td>
      <td>1479.0</td>
      <td>0.11100</td>
      <td>0.11590</td>
      <td>0.24390</td>
      <td>0.13890</td>
      <td>0.1726</td>
      <td>0.05623</td>
      <td>...</td>
      <td>25.450</td>
      <td>26.40</td>
      <td>166.10</td>
      <td>2027.0</td>
      <td>0.14100</td>
      <td>0.21130</td>
      <td>0.4107</td>
      <td>0.22160</td>
      <td>0.2060</td>
      <td>0.07115</td>
    </tr>
    <tr>
      <th>65</th>
      <td>20.130</td>
      <td>28.25</td>
      <td>131.20</td>
      <td>1261.0</td>
      <td>0.09780</td>
      <td>0.10340</td>
      <td>0.14400</td>
      <td>0.09791</td>
      <td>0.1752</td>
      <td>0.05533</td>
      <td>...</td>
      <td>23.690</td>
      <td>38.25</td>
      <td>155.00</td>
      <td>1731.0</td>
      <td>0.11660</td>
      <td>0.19220</td>
      <td>0.3215</td>
      <td>0.16280</td>
      <td>0.2572</td>
      <td>0.06637</td>
    </tr>
    <tr>
      <th>66</th>
      <td>16.600</td>
      <td>28.08</td>
      <td>108.30</td>
      <td>858.1</td>
      <td>0.08455</td>
      <td>0.10230</td>
      <td>0.09251</td>
      <td>0.05302</td>
      <td>0.1590</td>
      <td>0.05648</td>
      <td>...</td>
      <td>18.980</td>
      <td>34.12</td>
      <td>126.70</td>
      <td>1124.0</td>
      <td>0.11390</td>
      <td>0.30940</td>
      <td>0.3403</td>
      <td>0.14180</td>
      <td>0.2218</td>
      <td>0.07820</td>
    </tr>
    <tr>
      <th>67</th>
      <td>20.600</td>
      <td>29.33</td>
      <td>140.10</td>
      <td>1265.0</td>
      <td>0.11780</td>
      <td>0.27700</td>
      <td>0.35140</td>
      <td>0.15200</td>
      <td>0.2397</td>
      <td>0.07016</td>
      <td>...</td>
      <td>25.740</td>
      <td>39.42</td>
      <td>184.60</td>
      <td>1821.0</td>
      <td>0.16500</td>
      <td>0.86810</td>
      <td>0.9387</td>
      <td>0.26500</td>
      <td>0.4087</td>
      <td>0.12400</td>
    </tr>
    <tr>
      <th>68</th>
      <td>7.760</td>
      <td>24.54</td>
      <td>47.92</td>
      <td>181.0</td>
      <td>0.05263</td>
      <td>0.04362</td>
      <td>0.00000</td>
      <td>0.00000</td>
      <td>0.1587</td>
      <td>0.05884</td>
      <td>...</td>
      <td>9.456</td>
      <td>30.37</td>
      <td>59.16</td>
      <td>268.6</td>
      <td>0.08996</td>
      <td>0.06444</td>
      <td>0.0000</td>
      <td>0.00000</td>
      <td>0.2871</td>
      <td>0.07039</td>
    </tr>
  </tbody>
</table>
<p>69 rows × 30 columns</p>
</div>

<h2 id="3-model-training">3. Model training<a class="headerlink" href="#3-model-training" title="Permanent link">&para;</a></h2>
<div class="arithmatex">\[\vec{x}\in\mathbb{R}^{1\times 30}\]</div>
<div class="arithmatex">\[W\in\mathbb{R}^{30\times 1}\]</div>
<div class="arithmatex">\[b\in\mathbb{R}\]</div>
<div class="arithmatex">\[z = \vec{x}W+b\]</div>
<div class="arithmatex">\[\hat{y} = \sigma(z) = \frac{1}{1+e^{-z}}\]</div>
<hr />
<p><strong>Cross Entropy Loss Function</strong></p>
<div class="arithmatex">\[Loss(W，b) = -\frac{1}{N}\sum_{i = 1}^{N}[y_i\log\hat{y_i} + (1 - y_i)\log (1-\hat{y_i})]\]</div>
<hr />
<div class="arithmatex">\[k = 0,1,2,...\]</div>
<div class="arithmatex">\[W^{(k+1)}= W^{(k)} - \alpha_k\frac{\partial Loss (W^{(k)}, b^{(k)})}{\partial W}\]</div>
<div class="arithmatex">\[b^{(k+1)}= b^{(k)} - \alpha_k\frac{\partial Loss (W^{(k)}, b^{(k)})}{\partial b}\]</div>
<div class="highlight"><pre><span></span><code><span class="c1"># 使用 PyTorch 定义了两个可训练的变量（参数）：W 和 b</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">30</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<p>使用 <code>torch.tensor</code> 创建张量，并传入 <code>np.zeros((30, 1))</code> 来初始化权重 W，表示一个大小为 30x1 的全零张量。</p>
<p>使用 <code>dtype=torch.float32</code> 设置张量的数据类型为 float32。</p>
<p>设置 <code>requires_grad = True</code>，以便在计算中跟踪并计算梯度。</p>
<p>注意：在新版本的 PyTorch 中，<code>Variable</code> 被废弃了，直接使用 <code>torch.tensor</code> 创建张量即可。</p>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Initial value of w =&quot;</span><span class="p">,</span> <span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---------------------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Initial value of b =&quot;</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Initial value of w = tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0.]], grad_fn=&lt;PermuteBackward0&gt;)
---------------------------------------------------------
Initial value of b = tensor([0.], requires_grad=True)
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># 将 training_X 和 training_y 向量化（vertorization）处理</span>
<span class="n">X_vec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">training_X</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># N*30</span>
<span class="n">y_vec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">training_y</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># N*1</span>
</code></pre></div>
<p>使用 <code>torch.tensor</code> 创建张量，并传入 <code>training_X.values</code> 将 <code>training_X</code> 转换为张量 <code>X_vec</code>，数据类型设置为 float32。</p>
<p>使用 <code>torch.tensor</code> 创建张量，并传入 <code>training_y.values</code> 将 <code>training_y</code> 转换为张量 <code>y_vec</code>，数据类型设置为 float32，并使用 <code>reshape(-1, 1)</code> 将其形状改为 <code>N*1</code>，其中 N 表示样本数量。</p>
<div class="highlight"><pre><span></span><code><span class="n">X_vec</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>torch.Size([500, 30])
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">y_vec</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>torch.Size([500, 1])
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">Iter_times</span> <span class="o">=</span> <span class="mi">100000</span> <span class="c1"># 迭代次数</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.000015</span> <span class="c1"># 设置初始学习率</span>
<span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># 储存每一次迭代后的损失函数（如果递减，说明梯度下降是成功的）</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Iter_times</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">X_vec</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span> <span class="c1"># mm：矩阵乘法，500*1</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="c1"># 500*1</span>

    <span class="c1"># 交叉熵损失函数</span>
    <span class="n">loss_vec</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">y_vec</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">y_vec</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">))</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_vec</span><span class="p">)</span> <span class="c1"># 取平均</span>

    <span class="c1"># 求导</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># 获取梯度</span>
    <span class="n">grad_w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span>
    <span class="n">grad_b</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span>

    <span class="c1"># 学习率</span>
    <span class="n">alpha_temp</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mf">0.001</span> <span class="o">*</span> <span class="n">i</span><span class="p">)</span>

    <span class="c1"># 用alpha调整梯度</span>
    <span class="n">w</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">data</span> <span class="o">-</span> <span class="n">alpha_temp</span> <span class="o">*</span> <span class="n">grad_w</span>
    <span class="n">b</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">data</span> <span class="o">-</span> <span class="n">alpha_temp</span> <span class="o">*</span> <span class="n">grad_b</span>

    <span class="c1"># 开始下次梯度之前要清零（否则会不收敛）</span>
    <span class="n">w</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
    <span class="n">b</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

    <span class="c1"># 输出</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;iterations have been completed!&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;      -&gt; Now w1 =&quot;</span><span class="p">,</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;      -&gt; Now w2 =&quot;</span><span class="p">,</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;      -&gt; Now b =&quot;</span><span class="p">,</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;      -&gt; Now Loss =&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---------------------------------------------------------&quot;</span><span class="p">)</span>

    <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span>

    <span class="c1"># 当损失函数的变化 &lt; 10^-5 时，认为模型已经收敛到一个较好的解，无需继续迭代</span>
    <span class="k">if</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">loss_list</span><span class="p">[</span><span class="n">length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">loss_list</span><span class="p">[</span><span class="n">length</span> <span class="o">-</span> <span class="mi">2</span><span class="p">])</span> <span class="o">&lt;</span> <span class="mi">10</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">)</span> <span class="ow">and</span> <span class="n">length</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">):</span>
        <span class="k">break</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>1 iterations have been completed!
      -&gt; Now w1 = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(1.2350e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(2.8345, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2 iterations have been completed!
      -&gt; Now w1 = tensor(8.6309e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(1.2469e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.7095, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
3 iterations have been completed!
      -&gt; Now w1 = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(2.0564e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.4803, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
4 iterations have been completed!
      -&gt; Now w1 = tensor(9.7714e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(1.5858e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.9152, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
5 iterations have been completed!
      -&gt; Now w1 = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(2.4791e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(2.8352, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
6 iterations have been completed!
      -&gt; Now w1 = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(2.5471e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6368, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
7 iterations have been completed!
      -&gt; Now w1 = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(3.2530e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.0426, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
8 iterations have been completed!
      -&gt; Now w1 = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(2.7652e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.9973, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
9 iterations have been completed!
      -&gt; Now w1 = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(3.6527e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(2.7423, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
10 iterations have been completed!
      -&gt; Now w1 = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(3.6926e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6151, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
11 iterations have been completed!
      -&gt; Now w1 = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(4.3940e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.0319, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
12 iterations have been completed!
      -&gt; Now w1 = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(3.9090e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.8925, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
13 iterations have been completed!
      -&gt; Now w1 = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(4.7919e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(2.7136, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
14 iterations have been completed!
      -&gt; Now w1 = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(4.8531e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5777, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
15 iterations have been completed!
      -&gt; Now w1 = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(5.4751e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.8452, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
16 iterations have been completed!
      -&gt; Now w1 = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(5.0012e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.7197, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
17 iterations have been completed!
      -&gt; Now w1 = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(5.8802e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(2.7031, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
18 iterations have been completed!
      -&gt; Now w1 = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(5.9709e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5445, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
19 iterations have been completed!
      -&gt; Now w1 = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0010, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(6.4862e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6815, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
20 iterations have been completed!
      -&gt; Now w1 = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(6.0524e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.3842, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
21 iterations have been completed!
      -&gt; Now w1 = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0010, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(6.9268e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(2.6696, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
22 iterations have been completed!
      -&gt; Now w1 = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0010, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(7.0253e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5230, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
23 iterations have been completed!
      -&gt; Now w1 = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0011, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(7.4795e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6129, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
24 iterations have been completed!
      -&gt; Now w1 = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0010, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(7.0936e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.1365, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
25 iterations have been completed!
      -&gt; Now w1 = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0012, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(7.9587e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(2.4876, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
26 iterations have been completed!
      -&gt; Now w1 = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0012, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(7.9610e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5413, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
27 iterations have been completed!
      -&gt; Now w1 = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0013, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(8.5724e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.8255, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
28 iterations have been completed!
      -&gt; Now w1 = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0012, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(8.1163e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.4633, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
29 iterations have been completed!
      -&gt; Now w1 = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0013, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(8.9789e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(2.5229, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
30 iterations have been completed!
      -&gt; Now w1 = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0013, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(9.0345e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5025, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
31 iterations have been completed!
      -&gt; Now w1 = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0014, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(9.5107e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6230, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
32 iterations have been completed!
      -&gt; Now w1 = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0013, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(9.1218e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.1088, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
33 iterations have been completed!
      -&gt; Now w1 = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0015, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(9.9724e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(2.3022, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
34 iterations have been completed!
      -&gt; Now w1 = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0014, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(9.9157e-05, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5447, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
35 iterations have been completed!
      -&gt; Now w1 = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0015, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.9003, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
36 iterations have been completed!
      -&gt; Now w1 = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0014, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.3358, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
37 iterations have been completed!
      -&gt; Now w1 = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0016, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(2.3390, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
38 iterations have been completed!
      -&gt; Now w1 = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0016, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5018, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
39 iterations have been completed!
      -&gt; Now w1 = tensor(0.0010, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0017, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6953, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
40 iterations have been completed!
      -&gt; Now w1 = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0016, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.1394, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
41 iterations have been completed!
      -&gt; Now w1 = tensor(0.0010, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0017, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(2.1576, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
42 iterations have been completed!
      -&gt; Now w1 = tensor(0.0010, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0017, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5405, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
43 iterations have been completed!
      -&gt; Now w1 = tensor(0.0010, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0018, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.8840, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
44 iterations have been completed!
      -&gt; Now w1 = tensor(0.0010, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0017, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.1882, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
45 iterations have been completed!
      -&gt; Now w1 = tensor(0.0011, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0019, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(2.1067, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
46 iterations have been completed!
      -&gt; Now w1 = tensor(0.0010, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0018, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5315, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
47 iterations have been completed!
      -&gt; Now w1 = tensor(0.0011, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0020, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.8397, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
48 iterations have been completed!
      -&gt; Now w1 = tensor(0.0010, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0019, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.1149, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
49 iterations have been completed!
      -&gt; Now w1 = tensor(0.0011, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0020, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.9685, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
50 iterations have been completed!
      -&gt; Now w1 = tensor(0.0011, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0020, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5624, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
51 iterations have been completed!
      -&gt; Now w1 = tensor(0.0012, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0021, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.9378, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
52 iterations have been completed!
      -&gt; Now w1 = tensor(0.0011, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0020, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.0626, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
53 iterations have been completed!
      -&gt; Now w1 = tensor(0.0012, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0021, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.8434, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
54 iterations have been completed!
      -&gt; Now w1 = tensor(0.0012, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0021, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5908, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
55 iterations have been completed!
      -&gt; Now w1 = tensor(0.0013, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0022, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.0015, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
56 iterations have been completed!
      -&gt; Now w1 = tensor(0.0012, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0021, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0001, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.9963, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
57 iterations have been completed!
      -&gt; Now w1 = tensor(0.0013, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.7073, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
58 iterations have been completed!
      -&gt; Now w1 = tensor(0.0012, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0022, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6266, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
59 iterations have been completed!
      -&gt; Now w1 = tensor(0.0013, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.0660, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
60 iterations have been completed!
      -&gt; Now w1 = tensor(0.0013, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.9267, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
61 iterations have been completed!
      -&gt; Now w1 = tensor(0.0014, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.5658, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
62 iterations have been completed!
      -&gt; Now w1 = tensor(0.0013, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6652, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
63 iterations have been completed!
      -&gt; Now w1 = tensor(0.0014, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.1180, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
64 iterations have been completed!
      -&gt; Now w1 = tensor(0.0013, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.8610, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
65 iterations have been completed!
      -&gt; Now w1 = tensor(0.0014, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.4258, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
66 iterations have been completed!
      -&gt; Now w1 = tensor(0.0014, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.7004, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
67 iterations have been completed!
      -&gt; Now w1 = tensor(0.0015, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.1473, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
68 iterations have been completed!
      -&gt; Now w1 = tensor(0.0014, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.8065, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
69 iterations have been completed!
      -&gt; Now w1 = tensor(0.0015, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.2985, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
70 iterations have been completed!
      -&gt; Now w1 = tensor(0.0014, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.7239, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
71 iterations have been completed!
      -&gt; Now w1 = tensor(0.0015, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.1463, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
72 iterations have been completed!
      -&gt; Now w1 = tensor(0.0015, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.7671, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
73 iterations have been completed!
      -&gt; Now w1 = tensor(0.0016, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.1932, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
74 iterations have been completed!
      -&gt; Now w1 = tensor(0.0015, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.7316, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
75 iterations have been completed!
      -&gt; Now w1 = tensor(0.0016, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.1162, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
76 iterations have been completed!
      -&gt; Now w1 = tensor(0.0015, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.7412, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
77 iterations have been completed!
      -&gt; Now w1 = tensor(0.0016, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.1103, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
78 iterations have been completed!
      -&gt; Now w1 = tensor(0.0016, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.7261, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
79 iterations have been completed!
      -&gt; Now w1 = tensor(0.0017, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.0669, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
80 iterations have been completed!
      -&gt; Now w1 = tensor(0.0016, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.7225, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
81 iterations have been completed!
      -&gt; Now w1 = tensor(0.0017, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.0420, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
82 iterations have been completed!
      -&gt; Now w1 = tensor(0.0016, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.7133, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
83 iterations have been completed!
      -&gt; Now w1 = tensor(0.0017, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(1.0094, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
84 iterations have been completed!
      -&gt; Now w1 = tensor(0.0017, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.7058, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
85 iterations have been completed!
      -&gt; Now w1 = tensor(0.0017, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.9801, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
86 iterations have been completed!
      -&gt; Now w1 = tensor(0.0017, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6972, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
87 iterations have been completed!
      -&gt; Now w1 = tensor(0.0018, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.9502, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
88 iterations have been completed!
      -&gt; Now w1 = tensor(0.0017, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6883, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
89 iterations have been completed!
      -&gt; Now w1 = tensor(0.0018, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.9208, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
90 iterations have been completed!
      -&gt; Now w1 = tensor(0.0018, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6791, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
91 iterations have been completed!
      -&gt; Now w1 = tensor(0.0018, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.8917, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
92 iterations have been completed!
      -&gt; Now w1 = tensor(0.0018, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6694, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
93 iterations have been completed!
      -&gt; Now w1 = tensor(0.0019, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.8629, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
94 iterations have been completed!
      -&gt; Now w1 = tensor(0.0018, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6592, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
95 iterations have been completed!
      -&gt; Now w1 = tensor(0.0019, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.8346, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
96 iterations have been completed!
      -&gt; Now w1 = tensor(0.0018, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6487, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
97 iterations have been completed!
      -&gt; Now w1 = tensor(0.0019, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.8066, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
98 iterations have been completed!
      -&gt; Now w1 = tensor(0.0019, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6377, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
99 iterations have been completed!
      -&gt; Now w1 = tensor(0.0019, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.7790, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
100 iterations have been completed!
      -&gt; Now w1 = tensor(0.0019, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6263, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
101 iterations have been completed!
      -&gt; Now w1 = tensor(0.0020, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.7519, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
102 iterations have been completed!
      -&gt; Now w1 = tensor(0.0019, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6145, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
103 iterations have been completed!
      -&gt; Now w1 = tensor(0.0020, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.7254, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
104 iterations have been completed!
      -&gt; Now w1 = tensor(0.0019, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6023, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
105 iterations have been completed!
      -&gt; Now w1 = tensor(0.0020, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6993, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
106 iterations have been completed!
      -&gt; Now w1 = tensor(0.0020, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5897, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
107 iterations have been completed!
      -&gt; Now w1 = tensor(0.0020, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6739, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
108 iterations have been completed!
      -&gt; Now w1 = tensor(0.0020, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0002, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5767, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
109 iterations have been completed!
      -&gt; Now w1 = tensor(0.0020, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6490, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
110 iterations have been completed!
      -&gt; Now w1 = tensor(0.0020, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5634, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
111 iterations have been completed!
      -&gt; Now w1 = tensor(0.0021, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6247, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
112 iterations have been completed!
      -&gt; Now w1 = tensor(0.0020, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5498, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
113 iterations have been completed!
      -&gt; Now w1 = tensor(0.0021, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.6011, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
114 iterations have been completed!
      -&gt; Now w1 = tensor(0.0021, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5359, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
115 iterations have been completed!
      -&gt; Now w1 = tensor(0.0021, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5781, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
116 iterations have been completed!
      -&gt; Now w1 = tensor(0.0021, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5216, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
117 iterations have been completed!
      -&gt; Now w1 = tensor(0.0021, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5558, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
118 iterations have been completed!
      -&gt; Now w1 = tensor(0.0021, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5072, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
119 iterations have been completed!
      -&gt; Now w1 = tensor(0.0021, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5342, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
120 iterations have been completed!
      -&gt; Now w1 = tensor(0.0021, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.4926, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
121 iterations have been completed!
      -&gt; Now w1 = tensor(0.0022, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.5133, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
122 iterations have been completed!
      -&gt; Now w1 = tensor(0.0021, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.4780, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
123 iterations have been completed!
      -&gt; Now w1 = tensor(0.0022, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.4933, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
124 iterations have been completed!
      -&gt; Now w1 = tensor(0.0022, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.4634, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
125 iterations have been completed!
      -&gt; Now w1 = tensor(0.0022, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.4743, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
126 iterations have been completed!
      -&gt; Now w1 = tensor(0.0022, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.4492, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
127 iterations have been completed!
      -&gt; Now w1 = tensor(0.0022, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.4564, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
128 iterations have been completed!
      -&gt; Now w1 = tensor(0.0022, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.4354, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
129 iterations have been completed!
      -&gt; Now w1 = tensor(0.0022, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.4398, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
130 iterations have been completed!
      -&gt; Now w1 = tensor(0.0022, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.4224, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
131 iterations have been completed!
      -&gt; Now w1 = tensor(0.0022, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.4245, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
132 iterations have been completed!
      -&gt; Now w1 = tensor(0.0022, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.4103, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
133 iterations have been completed!
      -&gt; Now w1 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.4109, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
134 iterations have been completed!
      -&gt; Now w1 = tensor(0.0022, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3992, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
135 iterations have been completed!
      -&gt; Now w1 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3988, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
136 iterations have been completed!
      -&gt; Now w1 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3894, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
137 iterations have been completed!
      -&gt; Now w1 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3882, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
138 iterations have been completed!
      -&gt; Now w1 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3807, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
139 iterations have been completed!
      -&gt; Now w1 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3792, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
140 iterations have been completed!
      -&gt; Now w1 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3732, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
141 iterations have been completed!
      -&gt; Now w1 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3715, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
142 iterations have been completed!
      -&gt; Now w1 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3668, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
143 iterations have been completed!
      -&gt; Now w1 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3650, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
144 iterations have been completed!
      -&gt; Now w1 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3613, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
145 iterations have been completed!
      -&gt; Now w1 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3597, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
146 iterations have been completed!
      -&gt; Now w1 = tensor(0.0023, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3568, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
147 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3553, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
148 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3530, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
149 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3517, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
150 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3499, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
151 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3488, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
152 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3474, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
153 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3464, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
154 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3453, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
155 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3445, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
156 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3436, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
157 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3429, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
158 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3422, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
159 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3416, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
160 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3411, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
161 iterations have been completed!
      -&gt; Now w1 = tensor(0.0024, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3405, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
162 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3401, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
163 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3396, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
164 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3392, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
165 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3388, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
166 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3384, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
167 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3380, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
168 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3377, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
169 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3373, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
170 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3370, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
171 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3367, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
172 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3363, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
173 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3360, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
174 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3357, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
175 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3354, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
176 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3351, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
177 iterations have been completed!
      -&gt; Now w1 = tensor(0.0025, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3348, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
178 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3345, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
179 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3341, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
180 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3338, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
181 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3335, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
182 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3332, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
183 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3330, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
184 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3327, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
185 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3324, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
186 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3321, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
187 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3318, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
188 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3315, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
189 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3312, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
190 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3309, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
191 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3306, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
192 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3303, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
193 iterations have been completed!
      -&gt; Now w1 = tensor(0.0026, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3301, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
194 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3298, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
195 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3295, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
196 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3292, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
197 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3289, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
198 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3286, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
199 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3284, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
200 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3281, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
201 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3278, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
202 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3275, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
203 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3273, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
204 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3270, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
205 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3267, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
206 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3265, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
207 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0003, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3262, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
208 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3259, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
209 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3257, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
210 iterations have been completed!
      -&gt; Now w1 = tensor(0.0027, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3254, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
211 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3251, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
212 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3249, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
213 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3246, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
214 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3243, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
215 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3241, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
216 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3238, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
217 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3236, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
218 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3233, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
219 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3230, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
220 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3228, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
221 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3225, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
222 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3223, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
223 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3220, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
224 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3218, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
225 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3215, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
226 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3213, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
227 iterations have been completed!
      -&gt; Now w1 = tensor(0.0028, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3210, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
228 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3208, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
229 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3205, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
230 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3203, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
231 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3200, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
232 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3198, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
233 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3196, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
234 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3193, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
235 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3191, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
236 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3188, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
237 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3186, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
238 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3184, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
239 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3181, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
240 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3179, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
241 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3176, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
242 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3174, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
243 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3172, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
244 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3169, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
245 iterations have been completed!
      -&gt; Now w1 = tensor(0.0029, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3167, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
246 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3165, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
247 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3163, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
248 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3160, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
249 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3158, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
250 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3156, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
251 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3153, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
252 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3151, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
253 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3149, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
254 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3147, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
255 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3145, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
256 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3142, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
257 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3140, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
258 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3138, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
259 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3136, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
260 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3134, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
261 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3131, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
262 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3129, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
263 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3127, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
264 iterations have been completed!
      -&gt; Now w1 = tensor(0.0030, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3125, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
265 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3123, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
266 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3121, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
267 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3119, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
268 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3116, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
269 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3114, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
270 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3112, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
271 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3110, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
272 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3108, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
273 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3106, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
274 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3104, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
275 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3102, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
276 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3100, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
277 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3098, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
278 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3096, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
279 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3094, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
280 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3092, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
281 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3090, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
282 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3088, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
283 iterations have been completed!
      -&gt; Now w1 = tensor(0.0031, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3086, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
284 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3084, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
285 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3082, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
286 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3080, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
287 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3078, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
288 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3076, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
289 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3074, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
290 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3072, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
291 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3070, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
292 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3068, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
293 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3066, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
294 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3064, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
295 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3062, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
296 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3061, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
297 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3059, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
298 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3057, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
299 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3055, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
300 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3053, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
301 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3051, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
302 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3049, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
303 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3047, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
304 iterations have been completed!
      -&gt; Now w1 = tensor(0.0032, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3046, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
305 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3044, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
306 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3042, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
307 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3040, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
308 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3038, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
309 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3037, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
310 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3035, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
311 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3033, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
312 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3031, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
313 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3029, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
314 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3028, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
315 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3026, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
316 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3024, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
317 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3022, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
318 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3021, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
319 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3019, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
320 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3017, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
321 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3016, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
322 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3014, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
323 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3012, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
324 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3010, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
325 iterations have been completed!
      -&gt; Now w1 = tensor(0.0033, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3009, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
326 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3007, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
327 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3005, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
328 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3004, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
329 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3002, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
330 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.3000, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
331 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2999, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
332 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2997, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
333 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2996, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
334 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2994, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
335 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2992, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
336 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2991, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
337 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2989, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
338 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2987, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
339 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2986, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
340 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2984, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
341 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2983, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
342 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2981, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
343 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2980, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
344 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2978, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
345 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2976, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
346 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2975, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
347 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2973, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
348 iterations have been completed!
      -&gt; Now w1 = tensor(0.0034, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2972, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
349 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0004, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2970, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
350 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2969, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
351 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2967, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
352 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2966, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
353 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2964, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
354 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2963, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
355 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2961, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
356 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2960, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
357 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2958, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
358 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2957, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
359 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2955, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
360 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2954, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
361 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2952, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
362 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2951, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
363 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2949, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
364 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2948, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
365 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2946, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
366 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2945, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
367 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2944, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
368 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2942, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
369 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2941, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
370 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2939, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
371 iterations have been completed!
      -&gt; Now w1 = tensor(0.0035, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2938, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
372 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2936, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
373 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2935, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
374 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2934, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
375 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2932, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
376 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2931, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
377 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2929, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
378 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2928, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
379 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2927, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
380 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2925, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
381 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2924, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
382 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2923, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
383 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2921, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
384 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2920, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
385 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2919, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
386 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2917, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
387 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2916, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
388 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2915, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
389 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2913, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
390 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2912, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
391 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2911, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
392 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2909, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
393 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2908, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
394 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2907, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
395 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2905, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
396 iterations have been completed!
      -&gt; Now w1 = tensor(0.0036, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2904, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
397 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2903, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
398 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2902, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
399 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2900, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
400 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2899, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
401 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2898, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
402 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2897, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
403 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2895, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
404 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2894, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
405 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2893, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
406 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2892, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
407 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2890, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
408 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2889, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
409 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2888, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
410 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2887, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
411 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2885, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
412 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2884, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
413 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2883, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
414 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2882, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
415 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2881, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
416 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2879, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
417 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2878, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
418 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2877, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
419 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2876, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
420 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2875, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
421 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2873, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
422 iterations have been completed!
      -&gt; Now w1 = tensor(0.0037, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2872, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
423 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2871, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
424 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2870, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
425 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2869, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
426 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2868, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
427 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2866, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
428 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2865, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
429 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2864, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
430 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2863, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
431 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2862, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
432 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2861, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
433 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2860, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
434 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0066, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2859, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
435 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2857, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
436 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2856, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
437 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2855, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
438 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2854, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
439 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2853, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
440 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2852, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
441 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2851, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
442 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2850, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
443 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2849, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
444 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2848, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
445 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2846, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
446 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2845, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
447 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2844, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
448 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2843, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
449 iterations have been completed!
      -&gt; Now w1 = tensor(0.0038, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2842, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
450 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2841, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
451 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2840, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
452 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0067, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2839, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
453 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2838, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
454 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2837, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
455 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2836, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
456 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2835, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
457 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2834, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
458 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2833, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
459 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2832, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
460 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2831, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
461 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2830, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
462 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2829, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
463 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2828, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
464 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2827, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
465 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2826, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
466 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2825, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
467 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2824, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
468 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2823, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
469 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2822, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
470 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0068, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2821, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
471 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2820, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
472 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2819, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
473 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2818, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
474 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2817, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
475 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2816, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
476 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2815, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
477 iterations have been completed!
      -&gt; Now w1 = tensor(0.0039, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2814, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
478 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2813, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
479 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2812, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
480 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2811, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
481 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2810, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
482 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2809, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
483 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2808, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
484 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2807, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
485 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2806, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
486 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2805, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
487 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2804, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
488 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2803, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
489 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0069, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2802, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
490 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2801, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
491 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2800, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
492 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2799, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
493 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2798, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
494 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2798, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
495 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2797, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
496 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2796, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
497 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2795, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
498 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2794, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
499 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2793, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
500 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2792, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
501 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2791, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
502 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2790, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
503 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2789, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
504 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2788, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
505 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2788, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
506 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2787, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
507 iterations have been completed!
      -&gt; Now w1 = tensor(0.0040, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2786, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
508 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2785, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
509 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0070, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2784, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
510 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2783, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
511 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2782, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
512 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2781, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
513 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2780, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
514 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2780, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
515 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2779, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
516 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2778, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
517 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2777, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
518 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2776, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
519 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2775, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
520 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2774, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
521 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2774, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
522 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2773, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
523 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2772, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
524 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2771, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
525 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2770, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
526 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2769, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
527 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2769, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
528 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2768, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
529 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2767, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
530 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0071, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2766, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
531 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2765, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
532 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2764, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
533 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2764, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
534 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2763, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
535 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2762, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
536 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2761, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
537 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2760, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
538 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2759, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
539 iterations have been completed!
      -&gt; Now w1 = tensor(0.0041, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2759, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
540 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2758, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
541 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2757, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
542 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2756, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
543 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2755, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
544 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2755, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
545 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0005, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2754, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
546 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2753, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
547 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2752, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
548 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2751, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
549 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2751, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
550 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2750, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
551 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2749, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
552 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0072, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2748, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
553 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2748, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
554 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2747, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
555 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2746, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
556 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2745, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
557 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2744, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
558 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2744, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
559 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2743, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
560 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2742, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
561 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2741, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
562 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2741, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
563 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2740, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
564 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2739, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
565 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2738, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
566 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2738, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
567 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2737, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
568 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2736, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
569 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2735, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
570 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2735, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
571 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2734, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
572 iterations have been completed!
      -&gt; Now w1 = tensor(0.0042, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2733, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
573 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2732, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
574 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0073, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2732, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
575 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2731, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
576 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2730, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
577 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2729, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
578 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2729, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
579 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2728, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
580 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2727, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
581 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2727, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
582 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2726, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
583 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2725, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
584 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2724, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
585 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2724, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
586 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2723, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
587 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2722, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
588 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2722, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
589 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2721, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
590 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2720, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
591 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2719, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
592 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2719, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
593 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2718, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
594 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2717, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
595 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2717, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
596 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2716, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
597 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2715, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
598 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0074, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2715, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
599 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2714, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
600 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2713, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
601 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2713, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
602 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2712, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
603 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2711, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
604 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2710, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
605 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2710, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
606 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2709, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
607 iterations have been completed!
      -&gt; Now w1 = tensor(0.0043, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2708, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
608 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2708, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
609 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2707, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
610 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2706, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
611 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2706, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
612 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2705, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
613 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2704, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
614 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2704, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
615 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2703, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
616 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2702, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
617 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2702, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
618 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2701, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
619 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2700, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
620 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2700, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
621 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2699, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
622 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2699, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
623 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0075, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2698, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
624 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2697, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
625 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2697, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
626 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2696, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
627 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2695, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
628 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2695, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
629 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2694, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
630 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2693, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
631 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2693, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
632 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2692, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
633 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2691, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
634 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2691, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
635 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2690, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
636 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2690, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
637 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2689, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
638 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2688, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
639 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2688, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
640 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2687, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
641 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2686, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
642 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2686, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
643 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2685, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
644 iterations have been completed!
      -&gt; Now w1 = tensor(0.0044, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2685, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
645 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2684, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
646 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2683, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
647 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2683, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
648 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2682, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
649 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2682, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
650 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2681, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
651 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2680, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
652 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2680, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
653 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2679, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
654 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2679, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
655 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2678, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
656 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2677, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
657 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2677, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
658 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2676, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
659 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2676, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
660 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2675, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
661 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2674, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
662 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2674, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
663 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2673, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
664 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2673, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
665 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2672, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
666 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2671, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
667 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2671, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
668 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2670, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
669 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2670, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
670 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2669, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
671 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2668, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
672 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2668, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
673 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2667, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
674 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2667, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
675 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2666, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
676 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0077, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2666, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
677 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2665, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
678 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2664, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
679 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2664, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
680 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2663, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
681 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2663, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
682 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2662, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
683 iterations have been completed!
      -&gt; Now w1 = tensor(0.0045, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2662, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
684 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2661, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
685 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2660, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
686 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2660, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
687 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2659, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
688 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2659, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
689 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2658, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
690 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2658, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
691 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2657, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
692 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2657, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
693 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2656, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
694 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2655, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
695 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2655, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
696 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2654, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
697 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2654, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
698 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2653, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
699 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2653, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
700 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2652, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
701 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2652, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
702 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2651, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
703 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2651, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
704 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2650, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
705 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0078, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2649, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
706 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2649, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
707 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2648, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
708 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2648, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
709 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2647, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
710 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2647, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
711 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2646, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
712 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2646, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
713 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2645, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
714 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2645, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
715 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2644, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
716 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2644, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
717 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2643, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
718 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2643, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
719 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2642, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
720 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2642, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
721 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2641, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
722 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2641, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
723 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2640, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
724 iterations have been completed!
      -&gt; Now w1 = tensor(0.0046, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2639, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
725 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2639, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
726 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2638, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
727 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2638, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
728 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2637, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
729 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2637, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
730 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2636, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
731 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2636, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
732 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2635, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
733 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2635, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
734 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2634, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
735 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0079, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2634, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
736 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2633, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
737 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2633, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
738 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2632, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
739 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2632, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
740 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2631, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
741 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2631, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
742 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2630, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
743 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2630, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
744 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2629, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
745 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2629, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
746 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2628, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
747 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2628, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
748 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2627, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
749 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2627, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
750 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2626, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
751 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2626, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
752 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2625, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
753 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2625, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
754 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2624, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
755 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2624, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
756 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2624, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
757 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2623, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
758 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2623, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
759 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2622, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
760 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2622, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
761 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2621, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
762 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2621, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
763 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2620, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
764 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2620, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
765 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2619, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
766 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2619, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
767 iterations have been completed!
      -&gt; Now w1 = tensor(0.0047, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0080, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2618, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
768 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2618, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
769 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2617, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
770 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2617, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
771 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2616, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
772 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2616, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
773 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2615, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
774 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2615, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
775 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2615, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
776 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2614, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
777 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2614, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
778 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2613, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
779 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2613, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
780 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2612, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
781 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2612, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
782 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2611, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
783 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2611, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
784 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2610, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
785 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2610, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
786 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2609, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
787 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2609, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
788 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2609, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
789 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2608, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
790 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2608, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
791 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2607, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
792 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2607, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
793 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2606, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
794 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2606, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
795 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2605, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
796 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2605, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
797 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2605, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
798 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2604, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
799 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2604, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
800 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0081, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2603, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
801 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2603, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
802 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2602, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
803 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2602, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
804 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2601, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
805 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2601, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
806 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2601, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
807 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2600, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
808 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2600, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
809 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2599, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
810 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2599, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
811 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2598, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
812 iterations have been completed!
      -&gt; Now w1 = tensor(0.0048, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2598, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
813 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2598, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
814 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2597, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
815 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2597, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
816 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2596, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
817 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2596, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
818 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2595, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
819 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2595, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
820 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2595, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
821 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2594, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
822 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2594, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
823 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2593, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
824 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0006, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2593, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
825 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2592, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
826 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2592, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
827 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2592, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
828 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2591, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
829 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2591, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
830 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2590, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
831 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2590, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
832 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2589, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
833 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2589, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
834 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2589, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
835 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0082, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2588, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
836 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2588, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
837 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2587, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
838 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2587, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
839 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2587, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
840 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2586, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
841 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2586, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
842 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2585, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
843 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2585, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
844 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2585, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
845 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2584, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
846 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2584, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
847 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2583, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
848 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2583, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
849 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2582, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
850 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2582, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
851 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2582, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
852 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2581, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
853 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2581, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
854 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2580, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
855 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2580, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
856 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2580, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
857 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2579, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
858 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2579, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
859 iterations have been completed!
      -&gt; Now w1 = tensor(0.0049, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2578, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
860 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2578, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
861 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2578, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
862 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2577, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
863 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2577, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
864 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2576, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
865 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2576, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
866 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2576, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
867 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2575, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
868 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2575, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
869 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2575, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
870 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2574, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
871 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2574, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
872 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0083, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2573, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
873 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2573, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
874 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2573, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
875 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2572, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
876 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2572, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
877 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2571, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
878 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2571, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
879 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2571, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
880 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2570, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
881 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2570, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
882 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2570, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
883 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2569, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
884 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2569, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
885 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2568, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
886 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2568, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
887 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2568, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
888 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2567, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
889 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2567, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
890 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2567, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
891 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2566, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
892 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2566, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
893 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2565, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
894 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2565, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
895 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2565, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
896 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2564, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
897 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2564, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
898 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2564, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
899 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2563, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
900 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2563, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
901 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2562, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
902 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2562, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
903 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2562, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
904 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2561, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
905 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2561, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
906 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2561, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
907 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2560, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
908 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2560, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
909 iterations have been completed!
      -&gt; Now w1 = tensor(0.0050, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2559, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
910 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2559, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
911 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0084, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2559, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
912 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2558, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
913 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2558, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
914 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2558, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
915 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2557, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
916 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2557, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
917 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2557, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
918 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2556, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
919 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2556, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
920 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2556, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
921 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2555, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
922 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2555, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
923 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2554, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
924 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2554, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
925 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2554, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
926 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2553, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
927 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2553, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
928 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2553, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
929 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2552, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
930 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2552, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
931 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2552, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
932 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2551, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
933 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2551, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
934 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2551, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
935 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2550, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
936 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2550, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
937 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2550, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
938 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2549, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
939 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2549, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
940 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2549, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
941 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2548, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
942 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2548, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
943 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2547, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
944 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2547, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
945 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2547, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
946 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2546, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
947 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2546, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
948 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2546, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
949 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2545, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
950 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2545, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
951 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2545, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
952 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2544, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
953 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0085, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2544, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
954 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2544, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
955 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2543, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
956 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2543, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
957 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2543, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
958 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2542, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
959 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2542, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
960 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2542, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
961 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2541, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
962 iterations have been completed!
      -&gt; Now w1 = tensor(0.0051, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2541, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
963 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2541, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
964 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2540, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
965 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2540, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
966 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2540, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
967 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2539, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
968 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2539, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
969 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2539, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
970 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2538, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
971 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2538, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
972 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2538, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
973 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2537, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
974 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2537, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
975 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2537, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
976 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2536, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
977 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2536, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
978 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2536, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
979 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2535, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
980 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2535, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
981 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2535, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
982 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2534, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
983 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2534, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
984 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2534, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
985 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2534, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
986 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2533, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
987 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2533, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
988 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2533, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
989 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2532, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
990 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2532, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
991 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2532, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
992 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2531, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
993 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2531, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
994 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2531, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
995 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2530, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
996 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0086, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2530, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
997 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2530, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
998 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2529, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
999 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2529, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1000 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2529, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1001 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2528, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1002 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2528, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1003 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2528, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1004 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2528, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1005 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2527, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1006 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2527, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1007 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2527, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1008 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2526, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1009 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2526, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1010 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2526, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1011 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2525, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1012 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2525, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1013 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2525, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1014 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2524, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1015 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2524, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1016 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2524, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1017 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2524, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1018 iterations have been completed!
      -&gt; Now w1 = tensor(0.0052, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2523, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1019 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2523, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1020 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2523, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1021 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2522, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1022 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2522, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1023 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2522, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1024 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2521, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1025 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2521, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1026 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2521, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1027 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2520, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1028 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2520, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1029 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2520, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1030 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2520, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1031 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2519, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1032 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2519, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1033 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2519, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1034 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2518, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1035 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2518, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1036 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2518, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1037 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2518, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1038 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2517, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1039 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2517, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1040 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2517, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1041 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2516, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1042 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2516, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1043 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0087, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2516, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1044 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2515, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1045 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2515, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1046 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2515, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1047 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2515, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1048 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2514, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1049 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2514, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1050 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2514, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1051 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2513, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1052 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2513, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1053 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2513, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1054 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2513, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1055 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2512, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1056 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2512, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1057 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2512, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1058 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2511, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1059 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2511, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1060 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2511, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1061 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2511, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1062 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2510, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1063 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2510, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1064 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2510, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1065 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2509, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1066 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2509, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1067 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2509, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1068 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2509, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1069 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2508, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1070 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2508, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1071 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2508, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1072 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2507, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1073 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2507, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1074 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2507, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1075 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2507, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1076 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2506, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1077 iterations have been completed!
      -&gt; Now w1 = tensor(0.0053, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2506, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1078 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2506, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1079 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2505, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1080 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2505, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1081 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2505, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1082 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2505, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1083 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2504, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1084 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2504, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1085 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2504, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1086 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2504, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1087 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2503, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1088 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2503, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1089 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2503, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1090 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2502, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1091 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2502, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1092 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0088, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2502, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1093 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2502, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1094 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2501, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1095 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2501, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1096 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2501, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1097 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2501, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1098 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2500, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1099 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2500, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1100 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2500, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1101 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2499, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1102 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2499, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1103 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2499, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1104 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2499, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1105 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2498, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1106 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2498, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1107 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2498, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1108 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2498, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1109 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2497, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1110 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2497, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1111 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2497, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1112 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2497, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1113 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2496, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1114 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2496, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1115 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2496, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1116 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2495, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1117 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2495, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1118 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2495, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1119 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2495, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1120 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2494, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1121 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2494, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1122 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2494, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1123 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2494, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1124 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2493, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1125 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2493, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1126 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2493, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1127 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2493, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1128 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2492, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1129 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2492, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1130 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2492, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1131 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2492, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1132 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2491, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1133 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2491, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1134 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2491, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1135 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2491, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1136 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2490, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1137 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2490, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1138 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2490, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1139 iterations have been completed!
      -&gt; Now w1 = tensor(0.0054, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2489, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1140 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2489, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1141 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2489, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1142 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2489, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1143 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2488, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1144 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2488, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1145 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0089, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2488, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1146 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2488, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1147 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2487, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1148 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2487, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1149 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2487, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1150 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2487, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1151 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2486, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1152 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2486, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1153 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2486, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1154 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2486, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1155 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2485, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1156 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2485, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1157 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2485, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1158 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2485, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1159 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2484, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1160 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2484, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1161 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2484, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1162 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2484, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1163 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2483, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1164 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2483, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1165 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2483, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1166 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2483, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1167 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2482, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1168 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2482, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1169 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2482, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1170 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2482, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1171 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2481, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1172 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2481, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1173 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2481, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1174 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2481, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1175 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2481, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1176 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2480, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1177 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2480, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1178 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2480, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1179 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2480, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1180 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2479, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1181 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2479, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1182 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2479, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1183 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2479, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1184 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2478, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1185 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2478, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1186 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2478, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1187 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2478, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1188 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2477, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1189 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2477, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1190 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2477, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1191 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2477, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1192 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2476, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1193 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2476, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1194 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2476, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1195 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2476, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1196 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2475, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1197 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2475, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1198 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2475, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1199 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2475, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1200 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2475, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1201 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0090, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2474, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1202 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2474, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1203 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2474, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1204 iterations have been completed!
      -&gt; Now w1 = tensor(0.0055, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2474, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1205 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2473, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1206 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2473, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1207 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2473, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1208 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2473, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1209 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2472, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1210 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2472, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1211 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2472, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1212 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2472, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1213 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2472, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1214 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2471, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1215 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2471, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1216 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2471, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1217 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2471, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1218 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2470, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1219 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2470, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1220 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2470, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1221 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2470, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1222 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2469, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1223 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2469, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1224 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0007, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2469, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1225 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2469, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1226 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2469, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1227 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2468, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1228 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2468, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1229 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2468, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1230 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2468, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1231 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2467, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1232 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2467, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1233 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2467, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1234 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2467, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1235 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2467, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1236 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2466, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1237 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2466, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1238 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2466, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1239 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2466, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1240 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2465, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1241 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2465, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1242 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2465, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1243 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2465, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1244 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2465, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1245 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2464, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1246 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2464, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1247 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2464, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1248 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2464, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1249 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2463, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1250 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2463, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1251 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2463, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1252 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2463, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1253 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2463, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1254 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2462, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1255 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2462, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1256 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2462, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1257 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2462, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1258 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2461, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1259 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2461, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1260 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2461, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1261 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0091, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2461, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1262 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2461, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1263 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2460, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1264 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2460, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1265 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2460, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1266 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2460, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1267 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2459, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1268 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2459, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1269 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2459, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1270 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2459, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1271 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2459, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1272 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2458, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1273 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2458, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1274 iterations have been completed!
      -&gt; Now w1 = tensor(0.0056, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2458, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1275 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2458, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1276 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2458, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1277 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2457, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1278 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2457, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1279 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2457, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1280 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2457, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1281 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2456, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1282 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2456, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1283 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2456, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1284 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2456, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1285 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2456, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1286 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2455, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1287 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2455, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1288 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2455, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1289 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2455, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1290 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2455, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1291 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2454, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1292 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2454, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1293 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2454, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1294 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2454, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1295 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2454, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1296 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2453, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1297 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2453, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1298 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2453, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1299 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2453, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1300 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2453, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1301 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2452, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1302 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2452, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1303 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2452, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1304 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2452, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1305 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2451, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1306 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2451, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1307 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2451, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1308 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2451, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1309 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2451, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1310 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2450, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1311 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2450, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1312 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2450, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1313 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2450, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1314 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2450, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1315 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2449, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1316 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2449, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1317 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2449, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1318 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2449, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1319 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2449, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1320 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2448, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1321 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2448, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1322 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2448, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1323 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2448, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1324 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2448, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1325 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0092, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2447, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1326 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2447, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1327 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2447, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1328 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2447, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1329 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2447, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1330 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2446, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1331 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2446, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1332 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2446, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1333 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2446, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1334 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2446, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1335 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2445, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1336 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2445, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1337 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2445, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1338 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2445, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1339 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2445, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1340 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2444, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1341 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2444, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1342 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2444, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1343 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2444, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1344 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2444, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1345 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2443, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1346 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2443, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1347 iterations have been completed!
      -&gt; Now w1 = tensor(0.0057, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2443, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1348 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2443, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1349 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2443, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1350 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2442, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1351 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2442, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1352 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2442, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1353 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2442, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1354 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2442, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1355 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2442, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1356 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2441, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1357 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2441, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1358 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2441, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1359 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2441, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1360 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2441, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1361 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2440, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1362 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2440, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1363 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2440, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1364 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2440, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1365 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2440, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1366 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2439, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1367 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2439, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1368 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2439, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1369 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2439, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1370 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2439, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1371 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2438, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1372 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2438, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1373 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2438, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1374 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2438, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1375 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2438, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1376 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2438, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1377 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2437, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1378 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2437, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1379 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2437, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1380 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2437, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1381 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2437, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1382 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2436, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1383 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2436, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1384 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2436, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1385 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2436, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1386 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2436, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1387 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2435, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1388 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2435, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1389 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2435, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1390 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2435, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1391 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2435, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1392 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2435, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1393 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2434, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1394 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0093, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2434, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1395 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2434, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1396 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2434, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1397 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2434, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1398 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2433, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1399 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2433, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1400 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2433, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1401 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2433, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1402 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2433, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1403 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2432, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1404 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2432, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1405 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2432, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1406 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2432, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1407 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2432, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1408 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2432, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1409 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2431, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1410 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2431, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1411 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2431, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1412 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2431, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1413 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2431, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1414 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2430, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1415 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2430, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1416 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2430, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1417 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2430, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1418 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2430, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1419 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2430, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1420 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2429, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1421 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2429, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1422 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2429, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1423 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2429, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1424 iterations have been completed!
      -&gt; Now w1 = tensor(0.0058, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2429, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1425 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2429, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1426 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2428, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1427 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2428, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1428 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2428, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1429 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2428, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1430 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2428, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1431 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2427, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1432 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2427, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1433 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2427, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1434 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2427, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1435 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2427, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1436 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2427, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1437 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2426, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1438 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2426, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1439 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2426, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1440 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2426, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1441 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2426, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1442 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2426, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1443 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2425, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1444 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2425, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1445 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2425, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1446 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2425, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1447 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2425, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1448 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2424, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1449 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2424, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1450 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2424, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1451 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2424, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1452 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2424, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1453 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2424, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1454 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2423, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1455 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2423, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1456 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2423, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1457 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2423, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1458 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2423, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1459 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2423, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1460 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2422, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1461 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2422, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1462 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2422, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1463 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2422, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1464 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2422, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1465 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2422, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1466 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2421, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1467 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2421, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1468 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0094, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2421, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1469 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2421, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1470 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2421, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1471 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2421, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1472 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2420, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1473 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2420, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1474 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2420, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1475 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2420, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1476 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2420, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1477 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2420, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1478 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2419, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1479 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2419, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1480 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2419, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1481 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2419, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1482 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2419, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1483 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2419, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1484 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2418, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1485 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2418, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1486 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2418, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1487 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2418, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1488 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2418, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1489 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2418, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1490 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2417, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1491 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2417, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1492 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2417, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1493 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2417, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1494 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2417, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1495 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2417, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1496 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2416, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1497 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2416, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1498 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2416, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1499 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2416, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1500 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2416, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1501 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2416, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1502 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2415, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1503 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2415, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1504 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2415, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1505 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2415, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1506 iterations have been completed!
      -&gt; Now w1 = tensor(0.0059, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2415, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1507 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2415, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1508 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2414, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1509 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2414, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1510 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2414, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1511 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2414, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1512 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2414, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1513 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2414, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1514 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2413, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1515 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2413, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1516 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2413, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1517 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2413, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1518 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2413, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1519 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2413, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1520 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2412, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1521 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2412, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1522 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2412, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1523 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2412, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1524 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2412, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1525 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2412, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1526 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2411, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1527 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2411, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1528 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2411, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1529 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2411, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1530 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2411, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1531 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2411, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1532 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2411, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1533 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2410, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1534 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2410, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1535 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2410, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1536 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2410, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1537 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2410, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1538 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2410, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1539 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2409, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1540 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2409, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1541 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2409, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1542 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2409, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1543 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2409, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1544 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2409, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1545 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2408, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1546 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2408, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1547 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2408, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1548 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2408, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1549 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0095, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2408, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1550 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2408, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1551 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2408, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1552 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2407, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1553 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2407, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1554 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2407, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1555 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2407, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1556 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2407, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1557 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2407, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1558 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2406, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1559 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2406, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1560 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2406, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1561 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2406, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1562 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2406, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1563 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2406, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1564 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2406, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1565 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2405, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1566 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2405, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1567 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2405, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1568 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2405, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1569 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2405, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1570 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2405, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1571 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2404, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1572 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2404, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1573 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2404, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1574 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2404, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1575 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2404, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1576 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2404, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1577 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2404, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1578 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2403, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1579 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2403, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1580 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2403, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1581 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2403, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1582 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2403, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1583 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2403, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1584 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2403, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1585 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2402, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1586 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2402, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1587 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2402, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1588 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2402, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1589 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2402, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1590 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2402, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1591 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2401, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1592 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2401, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1593 iterations have been completed!
      -&gt; Now w1 = tensor(0.0060, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2401, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1594 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2401, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1595 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2401, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1596 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2401, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1597 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2401, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1598 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2400, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1599 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2400, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1600 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2400, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1601 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2400, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1602 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2400, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1603 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2400, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1604 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2400, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1605 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2399, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1606 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2399, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1607 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2399, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1608 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2399, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1609 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2399, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1610 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2399, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1611 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2399, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1612 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2398, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1613 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2398, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1614 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2398, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1615 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2398, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1616 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2398, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1617 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2398, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1618 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2397, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1619 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2397, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1620 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2397, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1621 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2397, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1622 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2397, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1623 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2397, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1624 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2397, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1625 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2396, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1626 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2396, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1627 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2396, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1628 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2396, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1629 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2396, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1630 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2396, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1631 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2396, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1632 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2395, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1633 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2395, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1634 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2395, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1635 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2395, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1636 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0096, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2395, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1637 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2395, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1638 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2395, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1639 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2394, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1640 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2394, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1641 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2394, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1642 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2394, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1643 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2394, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1644 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2394, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1645 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2394, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1646 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2393, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1647 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2393, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1648 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2393, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1649 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2393, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1650 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2393, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1651 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2393, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1652 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2393, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1653 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2393, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1654 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2392, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1655 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2392, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1656 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2392, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1657 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2392, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1658 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2392, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1659 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2392, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1660 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2392, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1661 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2391, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1662 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2391, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1663 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2391, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1664 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2391, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1665 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2391, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1666 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2391, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1667 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2391, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1668 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2390, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1669 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2390, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1670 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2390, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1671 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2390, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1672 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2390, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1673 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2390, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1674 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2390, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1675 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2389, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1676 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2389, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1677 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2389, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1678 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2389, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1679 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2389, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1680 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2389, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1681 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2389, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1682 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2389, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1683 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2388, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1684 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2388, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1685 iterations have been completed!
      -&gt; Now w1 = tensor(0.0061, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2388, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1686 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2388, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1687 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2388, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1688 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2388, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1689 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2388, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1690 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2387, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1691 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2387, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1692 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2387, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1693 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2387, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1694 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2387, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1695 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2387, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1696 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2387, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1697 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2386, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1698 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2386, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1699 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2386, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1700 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2386, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1701 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2386, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1702 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2386, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1703 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2386, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1704 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2386, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1705 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2385, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1706 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2385, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1707 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2385, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1708 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2385, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1709 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2385, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1710 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2385, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1711 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2385, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1712 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2384, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1713 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2384, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1714 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2384, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1715 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2384, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1716 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2384, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1717 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2384, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1718 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2384, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1719 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2384, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1720 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2383, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1721 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2383, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1722 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2383, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1723 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2383, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1724 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2383, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1725 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2383, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1726 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2383, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1727 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2383, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1728 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2382, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1729 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2382, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1730 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2382, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1731 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2382, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1732 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0097, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2382, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1733 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2382, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1734 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2382, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1735 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2381, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1736 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2381, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1737 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2381, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1738 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2381, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1739 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2381, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1740 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2381, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1741 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2381, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1742 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2381, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1743 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2380, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1744 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2380, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1745 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2380, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1746 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2380, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1747 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2380, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1748 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2380, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1749 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2380, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1750 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2380, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1751 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2379, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1752 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2379, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1753 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2379, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1754 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2379, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1755 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2379, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1756 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2379, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1757 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2379, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1758 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2379, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1759 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2378, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1760 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2378, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1761 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2378, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1762 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2378, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1763 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2378, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1764 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2378, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1765 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2378, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1766 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2378, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1767 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2377, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1768 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2377, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1769 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2377, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1770 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2377, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1771 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2377, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1772 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2377, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1773 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2377, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1774 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2377, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1775 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2376, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1776 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2376, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1777 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2376, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1778 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2376, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1779 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2376, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1780 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2376, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1781 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2376, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1782 iterations have been completed!
      -&gt; Now w1 = tensor(0.0062, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2376, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1783 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2375, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1784 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2375, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1785 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2375, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1786 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2375, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1787 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2375, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1788 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2375, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1789 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2375, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1790 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2375, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1791 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2374, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1792 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2374, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1793 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2374, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1794 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2374, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1795 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2374, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1796 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2374, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1797 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2374, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1798 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2374, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1799 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2373, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1800 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2373, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1801 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2373, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1802 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2373, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1803 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2373, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1804 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2373, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1805 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2373, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1806 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2373, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1807 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2372, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1808 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2372, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1809 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0008, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2372, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1810 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2372, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1811 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2372, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1812 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2372, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1813 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2372, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1814 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2372, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1815 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2372, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1816 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2371, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1817 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2371, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1818 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2371, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1819 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2371, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1820 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2371, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1821 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2371, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1822 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2371, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1823 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2371, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1824 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2370, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1825 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2370, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1826 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2370, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1827 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2370, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1828 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2370, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1829 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2370, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1830 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2370, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1831 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2370, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1832 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2369, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1833 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2369, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1834 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2369, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1835 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2369, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1836 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0098, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2369, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1837 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2369, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1838 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2369, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1839 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2369, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1840 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2369, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1841 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2368, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1842 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2368, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1843 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2368, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1844 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2368, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1845 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2368, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1846 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2368, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1847 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2368, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1848 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2368, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1849 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2368, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1850 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2367, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1851 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2367, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1852 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2367, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1853 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2367, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1854 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2367, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1855 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2367, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1856 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2367, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1857 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2367, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1858 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2366, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1859 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2366, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1860 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2366, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1861 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2366, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1862 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2366, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1863 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2366, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1864 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2366, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1865 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2366, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1866 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2366, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1867 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2365, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1868 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2365, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1869 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2365, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1870 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2365, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1871 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2365, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1872 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2365, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1873 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2365, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1874 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2365, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1875 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2365, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1876 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2364, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1877 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2364, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1878 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2364, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1879 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2364, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1880 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2364, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1881 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2364, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1882 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2364, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1883 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2364, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1884 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2363, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1885 iterations have been completed!
      -&gt; Now w1 = tensor(0.0063, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2363, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1886 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2363, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1887 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2363, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1888 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2363, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1889 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2363, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1890 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2363, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1891 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2363, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1892 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2363, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1893 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2362, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1894 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2362, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1895 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2362, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1896 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2362, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1897 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2362, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1898 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2362, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1899 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2362, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1900 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2362, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1901 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2362, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1902 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2361, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1903 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2361, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1904 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2361, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1905 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2361, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1906 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2361, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1907 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2361, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1908 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2361, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1909 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2361, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1910 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2361, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1911 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2360, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1912 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2360, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1913 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2360, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1914 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2360, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1915 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2360, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1916 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2360, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1917 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2360, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1918 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2360, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1919 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2360, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1920 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2359, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1921 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2359, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1922 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2359, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1923 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2359, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1924 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2359, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1925 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2359, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1926 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2359, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1927 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2359, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1928 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2359, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1929 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2359, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1930 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2358, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1931 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2358, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1932 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2358, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1933 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2358, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1934 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2358, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1935 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2358, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1936 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2358, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1937 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2358, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1938 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2358, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1939 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2357, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1940 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2357, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1941 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2357, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1942 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2357, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1943 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2357, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1944 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2357, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1945 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2357, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1946 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2357, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1947 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2357, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1948 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2356, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1949 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2356, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1950 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2356, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1951 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2356, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1952 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0099, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2356, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1953 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2356, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1954 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2356, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1955 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2356, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1956 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2356, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1957 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2356, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1958 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2355, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1959 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2355, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1960 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2355, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1961 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2355, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1962 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2355, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1963 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2355, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1964 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2355, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1965 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2355, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1966 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2355, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1967 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2354, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1968 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2354, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1969 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2354, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1970 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2354, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1971 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2354, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1972 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2354, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1973 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2354, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1974 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2354, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1975 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2354, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1976 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2354, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1977 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2353, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1978 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2353, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1979 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2353, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1980 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2353, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1981 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2353, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1982 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2353, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1983 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2353, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1984 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2353, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1985 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2353, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1986 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2352, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1987 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2352, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1988 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2352, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1989 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2352, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1990 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2352, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1991 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2352, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1992 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2352, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1993 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2352, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1994 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2352, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1995 iterations have been completed!
      -&gt; Now w1 = tensor(0.0064, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2352, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1996 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2351, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1997 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2351, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1998 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2351, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
1999 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2351, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2000 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2351, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2001 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2351, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2002 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2351, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2003 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2351, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2004 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2351, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2005 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2351, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2006 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2350, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2007 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2350, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2008 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2350, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2009 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2350, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2010 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2350, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2011 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2350, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2012 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2350, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2013 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2350, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2014 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2350, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2015 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2350, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2016 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2349, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2017 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2349, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2018 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2349, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2019 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2349, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2020 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2349, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2021 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2349, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2022 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2349, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2023 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2349, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2024 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2349, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
2025 iterations have been completed!
      -&gt; Now w1 = tensor(0.0065, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now w2 = tensor(0.0100, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now b = tensor(0.0009, grad_fn=&lt;SelectBackward0&gt;)
      -&gt; Now Loss = tensor(0.2349, grad_fn=&lt;MeanBackward0&gt;)
---------------------------------------------------------
</code></pre></div>
<h2 id="4-visualization-of-the-cross-entropy-function">4. Visualization of the Cross Entropy Function<a class="headerlink" href="#4-visualization-of-the-cross-entropy-function" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The length of loss_list is:&quot;</span><span class="p">,</span> <span class="n">length</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">201</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">loss_list</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">200</span><span class="p">]],</span> <span class="s2">&quot;black&quot;</span><span class="p">)</span> <span class="c1"># 画前200个iter</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>The length of loss_list is: 2025
</code></pre></div>
<p><img alt="png" src="../output_26_1.png" /></p>
<p>在绘制图形时，尝试调用 <code>numpy()</code> 函数将具有梯度的张量转换为NumPy数组，但是具有梯度的张量不支持直接转换为NumPy数组。</p>
<p>为了解决这个问题，使用 <code>detach().numpy()</code> 方法将具有梯度的张量分离出来，并将其转换为NumPy数组。</p>
<h2 id="5-prediction-on-the-test-set-and-model-evaluation">5. Prediction on the test set and model evaluation<a class="headerlink" href="#5-prediction-on-the-test-set-and-model-evaluation" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="c1"># 调用测试集的数据</span>
<span class="n">X_vec_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test_X</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># N*30</span>
<span class="n">y_vec_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test_y</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># N*1</span>

<span class="c1"># 同样，还是向量化处理，得到预测的概率值</span>
<span class="n">z_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">X_vec_test</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>  <span class="c1"># 69*1</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z_test</span><span class="p">)</span>  <span class="c1"># 69*1，得到的是概率</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># 把连续的概率值y_pred转换成 0 or 1</span>
<span class="n">y_pred</span><span class="p">[</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">y_pred</span><span class="p">[</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>tensor([[1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,
         1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1.]],
       grad_fn=&lt;AsStridedBackward0&gt;)
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">test_y</span><span class="o">.</span><span class="n">T</span> <span class="c1"># 看看真实的测试集数据，.T表示转置</span>
</code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>59</th>
      <th>60</th>
      <th>61</th>
      <th>62</th>
      <th>63</th>
      <th>64</th>
      <th>65</th>
      <th>66</th>
      <th>67</th>
      <th>68</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 69 columns</p>
</div>

<div class="highlight"><pre><span></span><code><span class="n">y_pred_np</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">y_pred_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">y_pred_np</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of y_pred_p:&quot;</span><span class="p">,</span> <span class="n">y_pred_np</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Shape of y_pred_p: (69,)
</code></pre></div>
<p>将具有梯度的张量 <code>y_pred</code> 分离出来，并将其转换为NumPy数组。</p>
<p>首先，使用 <code>detach()</code> 方法将 <code>y_pred</code> 张量分离出来，这样就得到一个没有梯度的新张量。然后，使用 <code>numpy()</code> 方法将该新张量转换为NumPy数组。最后，使用 <code>np.squeeze()</code> 函数将数组中的维度为1的维度去除，得到一个形状更紧凑的数组。</p>
<div class="highlight"><pre><span></span><code><span class="c1"># 计算预测结果 y_pred_np 和测试集标签 test_y 的准确率</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_y</span><span class="p">,</span> <span class="n">y_pred_np</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The accuracy score is:&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>The accuracy score is: 0.9130434782608695
</code></pre></div>
<p><code>accuracy_score</code> 函数用于计算分类任务的准确率。</p>
<p><code>accuracy = accuracy_score(y_true, y_pred)</code></p>
<p>其中：</p>
<p><code>y_true</code> 是真实的标签，可以是一个一维数组或列表。</p>
<p><code>y_pred</code> 是预测的标签，可以是一个一维数组或列表，与 <code>y_true</code> 的长度必须相等。</p>
<div class="highlight"><pre><span></span><code>
</code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Jingxuan Wang
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tabs", "navigation.top", "navigation.indexes", "navigation.expand", "search.suggest", "search.highlight", "content.code.copy", "content.action.edit"], "search": "../../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="../../../../mkdocs/javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>